{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN version Laser Machine Listener: Preprocess\n",
    "\n",
    "Run `download.sh` before starting this, to download dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sampling_rate': 16000, 'duration': 1, 'hop_length': 253, 'fmin': 20, 'fmax': 8000, 'n_mels': 64, 'n_fft': 1280, 'audio_split': 'dont_crop', 'labels': ['background', 'cutting_in_focus', 'cutting_not_in_focus', 'marking', 'sleeping', 'waiting'], 'folder': PosixPath('.'), 'n_fold': 1, 'normalize': 'samplewise', 'valid_limit': None, 'random_state': 42, 'test_size': 0.2, 'batch_size': 32, 'learning_rate': 0.0001, 'epochs': 50, 'verbose': 2, 'best_weight_file': 'best_model_weight.h5', 'label2int': {'background': 0, 'cutting_in_focus': 1, 'cutting_not_in_focus': 2, 'marking': 3, 'sleeping': 4, 'waiting': 5}, 'num_classes': 6, 'samples': 16000, 'dims': [64, 64, 1]}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from lib_data_preprocess import *\n",
    "%matplotlib inline\n",
    "\n",
    "conf['test_size'] = 0.2\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a list of training samples\n",
    "\n",
    "As listed below, this dataset is quite small:\n",
    "\n",
    "- 6 classes\n",
    "- 12 audio samples\n",
    "\n",
    "And this dataset is following basic structure of Keras classification project; `classname/filename.wav`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('laser-machine-listener/data/sleeping/sleeping.wav'),\n",
       " PosixPath('laser-machine-listener/data/background/background.wav'),\n",
       " PosixPath('laser-machine-listener/data/marking/acrylic_marking.wav'),\n",
       " PosixPath('laser-machine-listener/data/marking/paper_marking.wav'),\n",
       " PosixPath('laser-machine-listener/data/marking/mdf_marking.wav'),\n",
       " PosixPath('laser-machine-listener/data/waiting/waiting.wav'),\n",
       " PosixPath('laser-machine-listener/data/cutting_not_in_focus/paper_cutting_not_in_focus.wav'),\n",
       " PosixPath('laser-machine-listener/data/cutting_not_in_focus/mdf_cutting_not_in_focus.wav'),\n",
       " PosixPath('laser-machine-listener/data/cutting_not_in_focus/acrylic_cutting_not_in_focus.wav'),\n",
       " PosixPath('laser-machine-listener/data/cutting_in_focus/acrylic_cutting_in_focus.wav'),\n",
       " PosixPath('laser-machine-listener/data/cutting_in_focus/mdf_cutting_in_focus.wav'),\n",
       " PosixPath('laser-machine-listener/data/cutting_in_focus/paper_cutting_in_focus.wav')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATAROOT = Path('laser-machine-listener/data')\n",
    "data_files = list(DATAROOT.glob('*/*.wav'))\n",
    "data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "\n",
    "`AudioDataPreprocessor` class can read `classname/filename.wav` style dataset, preprocess them, split them into train/valid set and finally write them to files.\n",
    "\n",
    "Preprocess converts audio into log mel-spectrogram, then populate many training samples from the one big log mel-spectrogram raw sample by random cropping. This will be done for all the original samples.\n",
    "\n",
    "In this case, there are only 12 original audio samples. Then 480 training & 120 validation samples are created.\n",
    "\n",
    "- One sample duration is 1 second which is defined by config.py as conf.duration.\n",
    "- Sample is a three dimentional, [64 n_mels, 64 time hops, 1 channel] vector.\n",
    "\n",
    "### This preprocessing intentionally leaks data\n",
    "\n",
    "Usually train/valid split shall be very clean, valid data is supposed be 'unseen' one.\n",
    "But this data set is a special case, all classes has only one sample from sound variations.\n",
    "\n",
    "Some class has 3 samples but these are ones from all different variations.\n",
    "So there's no way making train/valid samples from one same original audio.\n",
    "This shuffles data to do that.\n",
    "\n",
    "```Python\n",
    "dm.resuffle_train_valid()\n",
    "```\n",
    "\n",
    "Usually this should be fine.\n",
    "\n",
    "```Python\n",
    "dm = AudioDataPreprocessor(conf)\n",
    "dm.convert_by_exclusive_split(data_files)\n",
    "# dm.resuffle_train_valid()\n",
    "dm.write_all()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[background] has 1 files.\n",
      "train_valid_split [(64, 3668)] [(64, 917)]\n",
      "[cutting_in_focus] has 3 files.\n",
      "train_valid_split [(64, 17622), (64, 6522)] [(64, 7177)]\n",
      "[cutting_not_in_focus] has 3 files.\n",
      "train_valid_split [(64, 7152), (64, 6526)] [(64, 17825)]\n",
      "[marking] has 3 files.\n",
      "train_valid_split [(64, 7108), (64, 7096)] [(64, 5248)]\n",
      "[sleeping] has 1 files.\n",
      "train_valid_split [(64, 3478)] [(64, 869)]\n",
      "[waiting] has 1 files.\n",
      "train_valid_split [(64, 2905)] [(64, 726)]\n",
      "Set labels to config.py ['background', 'cutting_in_focus', 'cutting_not_in_focus', 'marking', 'sleeping', 'waiting']\n",
      "Re-shuffled train/valid split with test size = 0.2.\n",
      "Train set 480 samples.\n",
      "Valid set 120 samples.\n",
      "Wrote preprocessed training data.\n"
     ]
    }
   ],
   "source": [
    "dm = AudioDataPreprocessor(conf)\n",
    "dm.convert_by_exclusive_split(data_files)\n",
    "dm.resuffle_train_valid()\n",
    "dm.write_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapes for all X & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(480, 64, 64, 1), (120, 64, 64, 1), (480,), (120,)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a.shape for a in [dm.X_train, dm.X_valid, dm.y_train, dm.y_valid]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### idx_train & idx_valid\n",
    "\n",
    "These are used in FSDKaggle2018 dataset, works nothing for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 5, 4, 0, 2, 3, 0, 5, 0, 4, 0, 1, 1, 5, 4, 2, 0, 2, 2, 1, 0, 5,\n",
       "        2, 5, 4, 2, 0, 1, 3, 5, 5, 2, 1, 3, 2, 5, 1, 1, 5, 3, 4, 0, 1, 4,\n",
       "        0, 2, 5, 1, 0, 0, 3, 3, 1, 3, 5, 4, 2, 2, 1, 2, 0, 2, 4, 2, 3, 0,\n",
       "        4, 5, 1, 3, 3, 0, 5, 4, 5, 2, 3, 2, 3, 5, 3, 5, 5, 4, 0, 0, 1, 2,\n",
       "        4, 2, 2, 3, 0, 3, 3, 3, 2, 0, 5, 1, 1, 2, 2, 4, 0, 5, 1, 3, 3, 5,\n",
       "        2, 5, 4, 5, 4, 4, 4, 1, 0, 5]),\n",
       " array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.y_valid, np.load(dm.f('idx_valid.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 4, 2, 2, 1, 4, 3, 5, 5, 1, 5, 2, 1, 5, 2, 0, 1, 3, 0, 0, 2,\n",
       "       1, 1, 0, 1, 4, 5, 0, 0, 5, 2, 4, 4, 2, 3, 0, 5, 1, 1, 4, 2, 0, 5,\n",
       "       4, 1, 3, 3, 3, 4, 3, 3, 2, 5, 2, 0, 0, 0, 1, 3, 1, 3, 5, 5, 5, 4,\n",
       "       4, 5, 4, 3, 0, 1, 0, 2, 5, 3, 5, 4, 1, 1, 1, 5, 5, 2, 2, 3, 3, 3,\n",
       "       3, 5, 3, 3, 3, 1, 2, 1, 4, 0, 2, 0, 2, 5, 0, 3, 4, 5, 4, 3, 0, 4,\n",
       "       0, 5, 2, 0, 3, 0, 5, 3, 5, 3, 4, 4, 5, 1, 1, 3, 1, 5, 2, 0, 1, 0,\n",
       "       2, 3, 0, 0, 4, 2, 0, 3, 3, 3, 4, 2, 3, 2, 3, 1, 2, 4, 4, 3, 0, 0,\n",
       "       4, 4, 5, 0, 0, 4, 0, 0, 0, 5, 4, 5, 3, 2, 0, 5, 3, 0, 2, 0, 1, 2,\n",
       "       4, 2, 1, 4, 2, 1, 4, 1, 0, 3, 2, 4, 2, 2, 1, 1, 4, 0, 4, 1, 4, 0,\n",
       "       5, 4, 1, 4, 5, 0, 2, 4, 4, 4, 5, 0, 4, 0, 1, 3, 3, 3, 0, 1, 4, 4,\n",
       "       3, 2, 3, 1, 3, 1, 2, 0, 5, 3, 2, 4, 1, 5, 2, 1, 5, 4, 4, 1, 1, 1,\n",
       "       1, 1, 2, 5, 1, 4, 3, 3, 5, 1, 2, 2, 4, 3, 1, 5, 5, 0, 2, 4, 1, 5,\n",
       "       2, 4, 0, 2, 1, 3, 4, 5, 3, 4, 4, 5, 4, 5, 3, 1, 0, 5, 1, 2, 5, 5,\n",
       "       5, 4, 3, 1, 5, 2, 3, 3, 2, 3, 1, 5, 2, 4, 3, 2, 1, 1, 0, 4, 4, 2,\n",
       "       4, 5, 4, 1, 5, 3, 3, 0, 1, 4, 5, 1, 0, 0, 2, 0, 3, 1, 3, 2, 4, 1,\n",
       "       0, 0, 0, 2, 1, 2, 5, 0, 2, 3, 1, 0, 3, 1, 4, 1, 2, 5, 2, 0, 3, 2,\n",
       "       2, 4, 3, 4, 4, 3, 2, 0, 3, 4, 2, 5, 1, 2, 5, 3, 4, 2, 4, 2, 1, 3,\n",
       "       2, 0, 5, 0, 0, 5, 3, 4, 2, 1, 0, 2, 1, 2, 0, 3, 4, 3, 5, 4, 0, 1,\n",
       "       0, 5, 1, 5, 2, 0, 0, 1, 0, 0, 4, 2, 2, 0, 4, 3, 3, 5, 5, 5, 3, 2,\n",
       "       2, 5, 5, 1, 4, 0, 3, 1, 2, 0, 1, 5, 5, 4, 1, 4, 4, 3, 0, 3, 4, 3,\n",
       "       2, 5, 0, 5, 1, 3, 4, 2, 5, 1, 0, 5, 4, 3, 0, 3, 5, 2, 3, 2, 4, 5,\n",
       "       0, 4, 3, 1, 1, 4, 1, 5, 4, 2, 5, 1, 0, 0, 1, 3, 5, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
